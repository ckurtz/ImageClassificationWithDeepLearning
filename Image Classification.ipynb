{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdfTgF7QW3P"
      },
      "source": [
        "<img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/logo2.jpg?raw=1\" width=\"300\">\n",
        "\n",
        "# Master 2, track VMI - IFLCE015 Apprentissage profond pour la vision : TP1 Convolutional neural network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duf_mjg8QW3Q"
      },
      "source": [
        "Prérequis pour ce TP : disposer d'un compte Google\n",
        "* Télécharger ce projet GitHub sur votre machine locale\n",
        "* Uploader ensuite ce projet dans un dossier lié à votre compte Google Drive\n",
        "* Ouvrir Google Collab et rechercher votre projet\n",
        "* Vous pouvez alors exécuter les différentes étapes sucessivement de ce notebook en local sur le serveur Google Collab, ce qui vous évite de disposer d'un GPU en local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlZZ5yyvQW3R"
      },
      "source": [
        "## La classification\n",
        "La classification est un precessus qui prend une entrée une donnée (par exemple, une image et ses pixels) et qui repond par une decision en sortie (chien, chat, ...) ou la probabiltée de chacune des classes considérées.\n",
        "\n",
        "## Les réseaux de neurones convolutionnels (CNN)\n",
        "Les CNN sont des réseaux profonds composés de différentes couches dans le but d'extraire (d'apprendre) des caractéristiques permettant de différencier les classes traitées.\n",
        "\n",
        "<img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/architecture-cnn-fr.png?raw=1\" width=\"800\">\n",
        "\n",
        "## Types de couche\n",
        "\n",
        "### Couche de convolution\n",
        "Le principe de la convolution est de glisser un masque sur l'ensemble des pixels de l'image et de calculer le produit de convolution pour chacun des pixels couverts par ce masque.\n",
        "<img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/convolution-layer-a.png?raw=1\" width=\"500\">\n",
        "*Remarque : l'étape de convolution peut aussi être généralisée dans les cas 1D et 3D.*\n",
        "\n",
        "### Couche de pooling\n",
        "Cette couche a pour but de réduire la dimension spatiale afin de ne garder que les information pertinentes. En particulier, les types de pooling les plus populaires sont le max et l'average pooling.\n",
        "\n",
        "|   Max Pooling        |   Avreage Pooling   |\n",
        ":-------------------:  |  :-------------------------:\n",
        "|<img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/max-pooling-a.png?raw=1\" width=\"300\"> | <img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/average-pooling-a.png?raw=1\" width=\"300\">  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOAm7kd3QW3R"
      },
      "source": [
        "# CNN pour la classification d'images\n",
        "\n",
        "Dans ce TP, le but est d'utiliser l'approntissage profond pour faire une classification d'images. Pour cela, la necessité d'une base de donnée est indispenssable. Nous allons utiliser ici la base CIFARE10.\n",
        "\n",
        "## CIFARE10\n",
        "\n",
        "CIFAR10 est constituée de 10 classes avec 6000 images dans chaque classe, amenant à 60 000 images au total. Cet ensemble d'images est divisé en 2 sous-ensembles : un ensemble pour l'entraînement qui contient 50 000 images et un ensemble pour le test qui contient 10 000 images.\n",
        "\n",
        "Les classes de cette base de données sont :\n",
        "\n",
        "* airplane\n",
        "* automobile\n",
        "* bird\n",
        "* cat\n",
        "* deer\n",
        "* dog\n",
        "* frog\n",
        "* horse\n",
        "* ship\n",
        "* truck\n",
        "\n",
        "Les images de cette base sont de talle 3x32x32 (des imagettes en couleur RGB).\n",
        "\n",
        "<img src=\"https://github.com/ckurtz/ImageClassificationWithDeepLearning/blob/master/media/cifar10.png?raw=1\">\n",
        "\n",
        "## Chargement de la base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IoMnJTsQW3R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTSzQKJGQW3S"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "\n",
        "##########################################################################\n",
        "#    Chargement/telechargement de la base de TRAIN de CIFARE10           #\n",
        "##########################################################################\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "##########################################################################\n",
        "#    Chargement/telechargement de la base de TEST de CIFARE10            #\n",
        "##########################################################################\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "##########################################################################\n",
        "#   Definition du module pour parcourir les donnees                      #\n",
        "# Paramètres:                                                            #\n",
        "#       - Batchsize (nb d'images qui passent en une fois avant retropropagation)#\n",
        "#       - shuffle (ordre de passage aléatoire des images) :              #\n",
        "#                   Vrai      ---> lors de l'entraînement                #\n",
        "#                   Faux/Vrai ---> lors du test                          #\n",
        "#                                                                        #\n",
        "# * On va creer 2 modules : un pour le TRAIN et un pour le TEST          #\n",
        "##########################################################################\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osqnn43OQW3S"
      },
      "source": [
        "### Visualisation de quelques images de l'ensemble d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0_9qoqFQW3T"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    ##########################################################################################\n",
        "    #   Il faut transposée les images car PyTorch lis les image en [Chanels, Width, Height]  #\n",
        "    #   et pour les voir il faut qu'elles soient [Width, Height, Chanels]                    #\n",
        "    ##########################################################################################\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(16)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcLdXGfxQW3T"
      },
      "source": [
        "### Création d'un CNN simple avec 2 couches de convolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VCo-6LcQW3U"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=20 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 20 * 5 * 5) #flattening\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_xWsw1QW3U"
      },
      "source": [
        "### Definition de la fonction Loss et de l'optimizeur\n",
        "\n",
        "Exemple ici : Classification Cross-Entropy loss et SGD avec momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITKVtslpQW3U"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqQQZw-6QW3V"
      },
      "source": [
        "### Entraînement du reseau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gU6YfJqQW3V"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "#   * Fixer les paramètres de l'entraînement   #\n",
        "###############################################\n",
        "\n",
        "nb_epoch = 20 # Le nombre d'epoch\n",
        "loss_list = [] # liste qui va contenir la valeur du loss a chaque epoch\n",
        "accuracy_list = []\n",
        "for epoch in range(nb_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    nb_data = 0.\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)              # Forward\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()                    # Backward\n",
        "        optimizer.step()                   # optimize\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        nb_data += 1.\n",
        "\n",
        "    running_loss = running_loss / nb_data\n",
        "    loss_list.append(running_loss)\n",
        "\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy_list.append(correct / total)\n",
        "\n",
        "    print(\"Epoch \", epoch, \"; train loss = \", running_loss, \"; accuracy = \", correct / total)\n",
        "\n",
        "torch.save({\n",
        "                'nb_epoch': nb_epoch,\n",
        "                'model' : net.state_dict(),\n",
        "                'listLoss': loss_list,\n",
        "            }, \"modelNN.pth\")\n",
        "\n",
        "print('Finished Training and save the model as `modelNN.pth`')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dplmCijNQW3V"
      },
      "source": [
        "### Tracer la courbe du loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stSopVCGQW3V"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(len(loss_list)), loss_list)\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"loss curve\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(len(accuracy_list)), accuracy_list)\n",
        "\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"accuracy curve\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK7nNEt7QW3W"
      },
      "source": [
        "### Tester le modèle sur les données de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FA62XqXnQW3W"
      },
      "outputs": [],
      "source": [
        "# Charger un batch de l'ensemble de test\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Passer le batch dans le reseau\n",
        "outputs = net(images)\n",
        "predicted1 = torch.softmax(outputs.data, 1) #decision probabiliste (floue)\n",
        "\n",
        "_, predicted2 = torch.max(predicted1, 1) #decision dure (classification)\n",
        "\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted2[j]] for j in range(16)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPeKF2NFQW3W"
      },
      "source": [
        "## Evaluation du modèle\n",
        "\n",
        "### Taux de reconnaissance global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTJ7O5DHQW3W"
      },
      "outputs": [],
      "source": [
        "correct = 0.\n",
        "total = 0.\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %f %%' % ( 100. * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8esepoNIQW3X"
      },
      "source": [
        "### Taux de reconnaissance de chacune des classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hteki4m3QW3X"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %f %%' % (classes[i], 100. * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pll6Dt7YQW3X"
      },
      "source": [
        "## Exercices - A vous de jouer ...\n",
        "* 1) Essayer de faire varier le nombre d'epochs pour améliorer la capacité du réseau à discriminer les différentes catégories d'images. Quel est le nombre d'epochs optimal ?\n",
        "\n",
        "* 2) Pour ne pas tomber dans un phénomène de sur-apprentissage, modifier le code donné ci-dessus pour intégrer un ensemble de validation qui permet de déterminer les hyper-paramètres du réseau et notamment un nombre d'epochs adapté.\n",
        "\n",
        "* 3) Essayer de modifier l'architecture du réseau pour améliorer le taux de reconnaissance de ce dernier. Vous devez faire attention au nombre de filtres utilisés et à la dimension des données de sortie.\n",
        "\n",
        "* 4) Proposer une interface permettant de visualiser les sorties des filtres de la première couche.\n",
        "\n",
        "* 5) Refaire cet exercice en utilisant un autre réseau comme SqueezeNet déjà pré-entrainé sur ImageNet que vous affiner (fine-tuning) sur les classes de CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C9b-x0pQW3X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}